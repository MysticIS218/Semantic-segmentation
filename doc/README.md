Syed Alam & Anosh Abraham

In this markdown, we will go over the base performance of the semantic segmentation of satellite imagery given the seed repository and necessary adjustments we made to optimize performance. To begin in milestone-2, the given seed repository gave us an idea of what a basic form of semantic segmentation is capable of without any form of optimization. In this milestone (milestone-3) we used the evolution method to optimize the hyperparameters. Fine-tuning the model hyperparameters improves the model’s performance on a validation set. Hyperparameter evolution is a method of Hyperparameter Optimization using a Genetic Algorithm (GA) for optimization. 

We ran our program in order to get the 10 prediction images that would be compared to the testing label. Since the amount of time it would take to run 100 epochs was taking too long even with colab pro we reduced the number to 3 epochs to save time. Because of this the accuracy of the predictions are going to be noticeably less accurate than running through with 100 epochs. For some images the prediction was fairly accurate. For others it wasn’t accurate at all. Some of the testing labels don't line up with the testing image that was being displayed and or were blank. However, even with only 3 epochs, the predictions were fairly accurate to the testing image/label but lacked color and definition for some. For the preparation of data, we followed the guidelines laid out in the video by "Digital Sreeni" in that we began by first taking and "normalizing" the data given. In this case, it was a set of photos that were all of different sizes. Using patchify, we cut images into easily divisible sections. Each section was then placed into a numpy array. It is from that array that we begin to fed our training algorithm. Specifically, the images were broken up into patches that were easily divisible by 256 (2048 x 1024). To ensure that this had been done properly, we followed the example given and ran checks throughout the code to observe any results. Once the photos were in proper size, we began to replace the RGB pixel information with numpy int values. From there, we were able to begin properly processing the data and running the trainers. For training, we run a multiple unet model with a total loss function. In the modeling, we train in batch sizes of 16. In our case we simply chose to follow the guidelines and run one hundred total epochs for training this model. Noticeably, the performance here is subpar. The model takes a significant amount of time to train (5 hours). The loss was minimal throughout runtime, and rarely went over a value 1.03. This also had an effect on how the graphs look like for both the training and validation loss vs epochs with only three points being plotted on the line graph. The precision/recall curves weren't able to be plotted on time. The training loss and validation loss graph shows an underfit with a decreasing trend while the IoU graph shows a major overfit with an increasing trend. We could not get through with graphing the precision and recall curves on time so we cannot comment on the issue.

